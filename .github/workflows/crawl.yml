name: CFRP Daily Crawl

permissions:
  contents: write     # ← これを追加
  
on:
  schedule:
    - cron:  '0 5 * * *'   # 14:00 JST
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - name: Install deps
        run: pip install -r requirements.txt
      - name: Run crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scripts/crawl.py
      - name: Cleanup old raw data
        run: |
          echo "Cleaning up raw data older than 30 days..."
          python scripts/cleanup_raw.py --days 30
      - name: Commit changes
        run: |
          git config --local user.email "bot@users.noreply.github.com"
          git config --local user.name "bot"
          git add raw || true
          git commit -m "crawl ${{ github.run_id }} and cleanup old data" || true
          git push
