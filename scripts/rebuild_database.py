#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã«ã‚¯ãƒªã‚¢ã—ã¦éå»1ãƒ¶æœˆã®rawãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†æ§‹ç¯‰
"""
import os
import json
import glob
from datetime import datetime, timedelta
from pathlib import Path
from supabase import create_client, Client
from dateutil import parser as dtparser
import pytz

# Supabaseæ¥ç¶š
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

def clear_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã‚¯ãƒªã‚¢"""
    print("ğŸ—‘ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢ä¸­...")
    
    try:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‹ã‚‰å‰Šé™¤
        items_result = supabase.table("items").select("id").execute()
        if items_result.data:
            for item in items_result.data:
                supabase.table("items").delete().eq("id", item["id"]).execute()
        print(f"   itemså‰Šé™¤: {len(items_result.data)} ä»¶")
        
        sources_result = supabase.table("sources").select("id").execute()
        if sources_result.data:
            for source in sources_result.data:
                supabase.table("sources").delete().eq("id", source["id"]).execute()
        print(f"   sourceså‰Šé™¤: {len(sources_result.data)} ä»¶")
        
    except Exception as e:
        print(f"   âš ï¸ ã‚¯ãƒªã‚¢å‡¦ç†ã§ä¸€éƒ¨ã‚¨ãƒ©ãƒ¼: {e}")
        print("   ç¶šè¡Œã—ã¾ã™...")

def setup_sources():
    """åŸºæœ¬çš„ãªsourcesã‚’å†ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    print("ğŸ“ sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å†æ§‹ç¯‰ä¸­...")
    
    initial_sources = [
        {
            "name": "CompositesWorld",
            "urls": ["https://www.compositesworld.com/rss/news"],
            "parser": "rss",
            "acquisition_mode": "auto",
            "category": "news",
            "domain": "compositesworld.com",
            "country_code": "US",
            "relevance": 8
        },
        {
            "name": "arXiv CFRP papers", 
            "urls": ["https://export.arxiv.org/api/query?search_query=all:CFRP&max_results=50&sortBy=submittedDate&sortOrder=descending"],
            "parser": "rss",
            "acquisition_mode": "auto", 
            "category": "paper",
            "domain": "arxiv.org",
            "country_code": "US",
            "relevance": 9
        }
    ]
    
    for source in initial_sources:
        result = supabase.table("sources").insert(source).execute()
        print(f"   âœ“ {source['name']} è¿½åŠ ")
    
    return {src["name"]: src for src in initial_sources}

def safe_date(txt):
    """å®‰å…¨ãªæ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰"""
    try:
        if not txt:
            return None
        
        # æ—¥ä»˜ã‚’ãƒ‘ãƒ¼ã‚¹
        parsed_date = dtparser.parse(txt)
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯UTCã¨ä»®å®š
        if parsed_date.tzinfo is None:
            parsed_date = pytz.utc.localize(parsed_date)
        
        # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
        jst = pytz.timezone('Asia/Tokyo')
        japan_time = parsed_date.astimezone(jst)
        
        return japan_time.date().isoformat()
    except Exception:
        return None

def safe_datetime(txt):
    """å®‰å…¨ãªæ—¥æ™‚ãƒ‘ãƒ¼ã‚¹ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰"""
    try:
        if not txt:
            # ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“ã‚’è¿”ã™
            jst = pytz.timezone('Asia/Tokyo')
            return datetime.now(jst).isoformat()
        
        # æ—¥æ™‚ã‚’ãƒ‘ãƒ¼ã‚¹
        parsed_datetime = dtparser.parse(txt)
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯UTCã¨ä»®å®š
        if parsed_datetime.tzinfo is None:
            parsed_datetime = pytz.utc.localize(parsed_datetime)
        
        # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
        jst = pytz.timezone('Asia/Tokyo')
        japan_time = parsed_datetime.astimezone(jst)
        
        return japan_time.isoformat()
    except Exception:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç¾åœ¨ã®æ—¥æœ¬æ™‚é–“
        jst = pytz.timezone('Asia/Tokyo')
        return datetime.now(jst).isoformat()

def get_source_id_by_filename(filename, source_mapping):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰source_idã‚’ç‰¹å®š"""
    if "CompositesWorld" in filename:
        return source_mapping["CompositesWorld"]["id"] if "CompositesWorld" in source_mapping else 1
    elif "arXiv" in filename:
        return source_mapping["arXiv CFRP papers"]["id"] if "arXiv CFRP papers" in source_mapping else 2
    return None

def rebuild_items_from_raw():
    """rawãƒ‡ãƒ¼ã‚¿ã‹ã‚‰itemsã‚’å†æ§‹ç¯‰"""
    print("ğŸ”„ rawãƒ‡ãƒ¼ã‚¿ã‹ã‚‰itemsã‚’å†æ§‹ç¯‰ä¸­...")
    
    # sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç¾åœ¨ã®æƒ…å ±ã‚’å–å¾—
    sources_result = supabase.table("sources").select("*").execute()
    source_mapping = {s["name"]: s for s in sources_result.data}
    
    raw_dir = Path("raw")
    processed_count = 0
    
    # 1ãƒ¶æœˆå‰ã‹ã‚‰ä»Šæ—¥ã¾ã§
    start_date = datetime.now() - timedelta(days=30)
    
    for date_dir in sorted(raw_dir.glob("2025-*")):
        try:
            date_str = date_dir.name
            file_date = datetime.strptime(date_str, "%Y-%m-%d")
            
            # 1ãƒ¶æœˆå‰ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å‡¦ç†
            if file_date < start_date:
                continue
                
            print(f"   ğŸ“… {date_str} ã‚’å‡¦ç†ä¸­...")
            
            # å„JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            for json_file in date_dir.glob("*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        entries = json.load(f)
                    
                    source_id = get_source_id_by_filename(json_file.name, source_mapping)
                    if not source_id:
                        print(f"      âš ï¸ source_idç‰¹å®šå¤±æ•—: {json_file.name}")
                        continue
                    
                    # å„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’itemsã«è¿½åŠ 
                    for entry in entries:
                        # æ—¥æœ¬æ™‚é–“ã§ã®è¿½åŠ æ™‚åˆ»ã‚’è¨­å®šï¼ˆã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãªã—ã§ä¿å­˜ï¼‰
                        jst = pytz.timezone('Asia/Tokyo')
                        added_at_jst = datetime.now(jst).replace(tzinfo=None).isoformat()
                        
                        item_data = {
                            "src_type": "news" if "CompositesWorld" in json_file.name else "paper",
                            "source_id": source_id,
                            "title": entry.get("title"),
                            "url": entry.get("link") or entry.get("id"),
                            "pub_date": safe_date(entry.get("published") or entry.get("updated")),
                            "body": entry.get("content", [{}])[0].get("value") if entry.get("content") else entry.get("summary"),
                            "added_at": added_at_jst
                        }
                        
                        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
                        if not item_data["url"] or not item_data["title"]:
                            continue
                        
                        try:
                            result = supabase.table("items").upsert(item_data, on_conflict="url").execute()
                            processed_count += 1
                            
                            if processed_count % 50 == 0:
                                print(f"      ğŸ“Š {processed_count} ä»¶å‡¦ç†å®Œäº†")
                                
                        except Exception as e:
                            print(f"      âŒ ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
                
                except Exception as e:
                    print(f"      âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ {json_file}: {e}")
        
        except Exception as e:
            print(f"   âŒ æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¨ãƒ©ãƒ¼ {date_dir}: {e}")
    
    print(f"âœ… å†æ§‹ç¯‰å®Œäº†: {processed_count} ä»¶ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†æ§‹ç¯‰é–‹å§‹")
    print("=" * 50)
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv("SUPABASE_URL") or not os.getenv("SUPABASE_KEY"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    try:
        # Step 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒªã‚¢
        clear_database()
        
        # Step 2: åŸºæœ¬sourcesã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—  
        setup_sources()
        
        # Step 3: rawãƒ‡ãƒ¼ã‚¿ã‹ã‚‰itemså†æ§‹ç¯‰
        rebuild_items_from_raw()
        
        print("=" * 50)
        print("ğŸ‰ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # æœ€çµ‚ç¢ºèª
        items_count = supabase.table("items").select("id", count="exact").execute()
        sources_count = supabase.table("sources").select("id", count="exact").execute()
        
        print(f"ğŸ“Š æœ€çµ‚çµæœ:")
        print(f"   - Sources: {sources_count.count} ä»¶")
        print(f"   - Items: {items_count.count} ä»¶")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()