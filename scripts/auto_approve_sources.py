#!/usr/bin/env python3
"""
é«˜å“è³ªãªæƒ…å ±æºå€™è£œã‚’è‡ªå‹•æ‰¿èªã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å“è³ªã‚¹ã‚³ã‚¢ã¨æ¤œè¨¼çµæœã«åŸºã¥ã„ã¦è‡ªå‹•ã§Sourcesãƒ†ãƒ¼ãƒ–ãƒ«ã«è¿½åŠ 
"""
import os
import json
import glob
from datetime import datetime
from typing import List, Dict
from supabase import create_client, Client

# Supabaseæ¥ç¶š
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

class SourceAutoApprover:
    def __init__(self):
        self.approval_criteria = {
            'min_relevance_score': 0.7,      # é–¢é€£åº¦ã‚¹ã‚³ã‚¢æœ€ä½å€¤
            'min_occurrence_count': 5,        # æœ€ä½å‡ºç¾å›æ•°ï¼ˆè¨˜äº‹åˆ†æç”±æ¥ï¼‰
            'required_feed_validation': True,  # ãƒ•ã‚£ãƒ¼ãƒ‰æ¤œè¨¼å¿…é ˆ
            'blocked_domains': [              # ãƒ–ãƒ­ãƒƒã‚¯ãƒ‰ãƒ¡ã‚¤ãƒ³
                'spam.com', 'fake-news.com', 'low-quality.net'
            ],
            'trusted_domains': [              # ä¿¡é ¼ã§ãã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³
                'arxiv.org', 'mdpi.com', 'acmanet.org', 
                'sampe.org', 'avk-tv.de', 'manufacturing.net'
            ]
        }
        
    def load_candidate_files(self) -> List[Dict]:
        """å€™è£œãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        candidates = []
        
        # å€™è£œãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            '*_candidates_*.json',
            '*_source_candidates_*.json', 
            'article_source_candidates_*.json',
            'multilingual_sources_*.json'
        ]
        
        for pattern in patterns:
            files = glob.glob(pattern)
            for file_path in files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            for item in data:
                                item['source_file'] = file_path
                                candidates.append(item)
                        else:
                            print(f"è­¦å‘Š: {file_path} ã¯æœŸå¾…ã•ã‚Œã‚‹å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        return candidates
    
    def evaluate_source_quality(self, candidate: Dict) -> Dict:
        """æƒ…å ±æºã®å“è³ªã‚’è©•ä¾¡"""
        score = 0
        reasons = []
        
        # 1. é–¢é€£åº¦ã‚¹ã‚³ã‚¢è©•ä¾¡
        relevance = candidate.get('relevance_score', 0)
        if relevance >= 0.8:
            score += 30
            reasons.append(f"é«˜ã„é–¢é€£åº¦ã‚¹ã‚³ã‚¢ ({relevance:.2f})")
        elif relevance >= 0.6:
            score += 20
            reasons.append(f"ä¸­ç¨‹åº¦ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ ({relevance:.2f})")
        elif relevance >= 0.4:
            score += 10
            reasons.append(f"ä½ã„é–¢é€£åº¦ã‚¹ã‚³ã‚¢ ({relevance:.2f})")
        
        # 2. ãƒ‰ãƒ¡ã‚¤ãƒ³ä¿¡é ¼æ€§
        urls = candidate.get('urls', [])
        if urls:
            domain = urls[0].split('/')[2] if len(urls[0].split('/')) > 2 else ''
            
            if any(trusted in domain for trusted in self.approval_criteria['trusted_domains']):
                score += 25
                reasons.append(f"ä¿¡é ¼ã§ãã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ ({domain})")
            elif any(blocked in domain for blocked in self.approval_criteria['blocked_domains']):
                score -= 50
                reasons.append(f"ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ ({domain})")
        
        # 3. å‡ºç¾å›æ•°ï¼ˆè¨˜äº‹åˆ†æç”±æ¥ã®å ´åˆï¼‰
        occurrence = candidate.get('occurrence_count', 0)
        if occurrence >= 10:
            score += 20
            reasons.append(f"é«˜ã„å‡ºç¾å›æ•° ({occurrence}å›)")
        elif occurrence >= 5:
            score += 10
            reasons.append(f"ä¸­ç¨‹åº¦ã®å‡ºç¾å›æ•° ({occurrence}å›)")
        
        # 4. ãƒ•ã‚£ãƒ¼ãƒ‰æ¤œè¨¼æ¸ˆã¿
        if candidate.get('feed_url') and candidate.get('feed_validated', False):
            score += 15
            reasons.append("RSS ãƒ•ã‚£ãƒ¼ãƒ‰æ¤œè¨¼æ¸ˆã¿")
        
        # 5. è¨€èªãƒ»åœ°åŸŸã®å¤šæ§˜æ€§
        language = candidate.get('language', 'english')
        if language in ['chinese', 'german', 'japanese']:
            score += 10
            reasons.append(f"å¤šè¨€èªå¯¾å¿œ ({language})")
        
        # 6. ã‚«ãƒ†ã‚´ãƒªã®ä¾¡å€¤
        category = candidate.get('category', '')
        if category in ['research', 'industry_news']:
            score += 5
            reasons.append(f"ä¾¡å€¤ã®é«˜ã„ã‚«ãƒ†ã‚´ãƒª ({category})")
        
        return {
            'score': score,
            'reasons': reasons,
            'approved': score >= 70,  # 70ç‚¹ä»¥ä¸Šã§è‡ªå‹•æ‰¿èª
            'review_required': 40 <= score < 70  # 40-69ç‚¹ã¯æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼
        }
    
    def get_existing_sources(self) -> set:
        """æ—¢å­˜ã®ã‚½ãƒ¼ã‚¹URLã‚’å–å¾—"""
        try:
            result = supabase.table('sources').select('urls').execute()
            existing_urls = set()
            for source in result.data:
                if source.get('urls'):
                    existing_urls.update(source['urls'])
            return existing_urls
        except Exception as e:
            print(f"æ—¢å­˜ã‚½ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return set()
    
    def auto_approve_sources(self, dry_run: bool = False):
        """è‡ªå‹•æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œ"""
        candidates = self.load_candidate_files()
        existing_urls = self.get_existing_sources()
        
        print(f"ğŸ“‹ {len(candidates)} å€‹ã®å€™è£œã‚’è©•ä¾¡ä¸­...")
        
        approved_sources = []
        review_required = []
        rejected_sources = []
        
        for candidate in candidates:
            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            candidate_urls = candidate.get('urls', [])
            if not candidate_urls or any(url in existing_urls for url in candidate_urls):
                continue
            
            # å“è³ªè©•ä¾¡
            evaluation = self.evaluate_source_quality(candidate)
            candidate['evaluation'] = evaluation
            
            if evaluation['approved']:
                approved_sources.append(candidate)
            elif evaluation['review_required']:
                review_required.append(candidate)
            else:
                rejected_sources.append(candidate)
        
        # çµæœå‡ºåŠ›
        print(f"\nğŸ“Š è©•ä¾¡çµæœ:")
        print(f"âœ… è‡ªå‹•æ‰¿èª: {len(approved_sources)} ä»¶")
        print(f"ğŸ” æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦: {len(review_required)} ä»¶")
        print(f"âŒ å´ä¸‹: {len(rejected_sources)} ä»¶")
        
        # è‡ªå‹•æ‰¿èªã•ã‚ŒãŸæƒ…å ±æºã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
        if approved_sources and not dry_run:
            print(f"\nğŸ¤– è‡ªå‹•æ‰¿èªã•ã‚ŒãŸæƒ…å ±æºã‚’è¿½åŠ ä¸­...")
            for source in approved_sources:
                try:
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³æŠ½å‡º
                    urls = source.get('urls', [])
                    domain = None
                    if urls and len(urls) > 0:
                        try:
                            domain = urls[0].split('/')[2]
                        except:
                            domain = 'unknown.com'
                    
                    new_source = {
                        'name': source.get('name', 'Unknown Source'),
                        'urls': urls,
                        'parser': 'rss',
                        'acquisition_mode': 'auto',
                        'category': source.get('category', 'news'),
                        'domain': domain,
                        'country_code': source.get('country_code', 'US'),
                        'relevance': min(10, max(1, source.get('evaluation', {}).get('score', 50) // 10))  # 1-10ã®ç¯„å›²
                    }
                    
                    result = supabase.table('sources').insert(new_source).execute()
                    print(f"  âœ“ è¿½åŠ å®Œäº†: {new_source['name']}")
                    
                except Exception as e:
                    print(f"  âœ— è¿½åŠ ã‚¨ãƒ©ãƒ¼: {source.get('name', 'Unknown')} - {e}")
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_approval_report(approved_sources, review_required, rejected_sources, dry_run)
        
        return {
            'approved': len(approved_sources),
            'review_required': len(review_required), 
            'rejected': len(rejected_sources)
        }
    
    def generate_approval_report(self, approved: List[Dict], review: List[Dict], rejected: List[Dict], dry_run: bool):
        """æ‰¿èªçµæœãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"source_approval_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# æƒ…å ±æºè‡ªå‹•æ‰¿èªãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"**å®Ÿè¡Œæ—¥æ™‚:** {datetime.now().isoformat()}\n")
            f.write(f"**ãƒ¢ãƒ¼ãƒ‰:** {'ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³' if dry_run else 'å®Ÿéš›ã®è¿½åŠ '}\n\n")
            
            f.write(f"## ğŸ“Š æ¦‚è¦\n\n")
            f.write(f"- âœ… è‡ªå‹•æ‰¿èª: {len(approved)} ä»¶\n")
            f.write(f"- ğŸ” æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦: {len(review)} ä»¶\n")
            f.write(f"- âŒ å´ä¸‹: {len(rejected)} ä»¶\n\n")
            
            if approved:
                f.write(f"## âœ… è‡ªå‹•æ‰¿èªã•ã‚ŒãŸæƒ…å ±æº\n\n")
                for source in approved:
                    eval_data = source.get('evaluation', {})
                    f.write(f"### {source.get('name', 'Unknown')}\n")
                    f.write(f"- **URL:** {source.get('urls', ['N/A'])[0]}\n")
                    f.write(f"- **ã‚¹ã‚³ã‚¢:** {eval_data.get('score', 0)}\n")
                    f.write(f"- **ç†ç”±:** {', '.join(eval_data.get('reasons', []))}\n\n")
            
            if review:
                f.write(f"## ğŸ” æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦ãªæƒ…å ±æº\n\n")
                for source in review:
                    eval_data = source.get('evaluation', {})
                    f.write(f"### {source.get('name', 'Unknown')}\n")
                    f.write(f"- **URL:** {source.get('urls', ['N/A'])[0]}\n")
                    f.write(f"- **ã‚¹ã‚³ã‚¢:** {eval_data.get('score', 0)}\n")
                    f.write(f"- **ç†ç”±:** {', '.join(eval_data.get('reasons', []))}\n\n")
        
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")

def main():
    approver = SourceAutoApprover()
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv("SUPABASE_URL") or not os.getenv("SUPABASE_KEY"):
        print("ã‚¨ãƒ©ãƒ¼: SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ç¢ºèª
    dry_run = os.getenv("DRY_RUN", "false").lower() == "true"
    
    print("ğŸ¤– æƒ…å ±æºè‡ªå‹•æ‰¿èªã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    print(f"ğŸ“‹ ãƒ¢ãƒ¼ãƒ‰: {'ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³' if dry_run else 'å®Ÿéš›ã®è¿½åŠ '}")
    
    results = approver.auto_approve_sources(dry_run=dry_run)
    
    print(f"\nğŸ¯ å®Œäº†: {results['approved']} ä»¶æ‰¿èª, {results['review_required']} ä»¶è¦ãƒ¬ãƒ“ãƒ¥ãƒ¼")

if __name__ == "__main__":
    main()