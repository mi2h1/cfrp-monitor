#!/usr/bin/env python3
"""
GPTæä¾›ã®æƒ…å ±æºã‚«ãƒ†ã‚´ãƒªã«åŸºã¥ãè‡ªå‹•æ¢ç´¢
æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®é¡ä¼¼æƒ…å ±æºã‚’ç™ºè¦‹
"""
import os
import json
import requests
from datetime import datetime
from typing import List, Dict
from bs4 import BeautifulSoup
import time
import random

class GPTCategoryDiscoverer:
    def __init__(self):
        self.categories = {
            # æ—¥æœ¬ã®ç‚­ç´ ç¹Šç¶­ãƒ»è¤‡åˆææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼
            'japanese_carbon_fiber': {
                'keywords': ['ç‚­ç´ ç¹Šç¶­', 'ã‚«ãƒ¼ãƒœãƒ³ãƒ•ã‚¡ã‚¤ãƒãƒ¼', 'CFRP', 'è¤‡åˆææ–™', 'ã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆ'],
                'domains': ['toray.com', 'teijin.com', 'mitsubishichemical.com'],
                'search_terms': [
                    'ç‚­ç´ ç¹Šç¶­ãƒ¡ãƒ¼ã‚«ãƒ¼ æ—¥æœ¬',
                    'carbon fiber manufacturers Japan',
                    'CFRP æ—¥æœ¬ä¼æ¥­',
                    'è¤‡åˆææ–™ ãƒ¡ãƒ¼ã‚«ãƒ¼'
                ]
            },
            
            # æ¬§å·ã®åŒ–å­¦ãƒ»ææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼
            'european_materials': {
                'keywords': ['composite materials', 'carbon fiber', 'advanced materials', 'prepreg'],
                'domains': ['solvay.com', 'sglcarbon.com', 'hexcel.com'],
                'search_terms': [
                    'composite materials manufacturers Europe',
                    'carbon fiber companies Germany France',
                    'advanced materials Europe',
                    'prepreg manufacturers'
                ]
            },
            
            # æ—¥æœ¬ã®ç”£æ¥­å°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢
            'japanese_industry_media': {
                'keywords': ['è£½é€ æ¥­', 'åŒ–å­¦å·¥æ¥­', 'ææ–™', 'æŠ€è¡“', 'ãƒ‹ãƒ¥ãƒ¼ã‚¹'],
                'domains': ['nikkan.co.jp', 'chemicaldaily.co.jp', 'kogyo.co.jp'],
                'search_terms': [
                    'è£½é€ æ¥­ å°‚é–€ç´™',
                    'åŒ–å­¦å·¥æ¥­ ãƒ‹ãƒ¥ãƒ¼ã‚¹',
                    'ææ–™ç”£æ¥­ ãƒ¡ãƒ‡ã‚£ã‚¢',
                    'æŠ€è¡“æƒ…å ± æ—¥æœ¬'
                ]
            },
            
            # è¤‡åˆææ–™æ¥­ç•Œãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
            'composites_industry_media': {
                'keywords': ['composites', 'reinforced plastics', 'fiber reinforced', 'industry news'],
                'domains': ['jeccomposites.com', 'compositesworld.com', 'reinforcedplastics.com'],
                'search_terms': [
                    'composites industry news',
                    'fiber reinforced plastics media',
                    'composite materials publications',
                    'advanced materials magazines'
                ]
            },
            
            # ä¸­å›½ã®è¤‡åˆææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼ãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢
            'chinese_composites': {
                'keywords': ['å¤åˆææ–™', 'ç¢³çº¤ç»´', 'ç»ç’ƒçº¤ç»´', 'å…ˆè¿›ææ–™', 'å¤æ'],
                'domains': ['chinacompositesexpo.com', 'composite.cn'],
                'search_terms': [
                    'å¤åˆææ–™ åˆ¶é€ å•† ä¸­å›½',
                    'ç¢³çº¤ç»´ ä¼ä¸š',
                    'China composites manufacturers',
                    'å¤åˆææ–™ æ–°é—»ç½‘ç«™',
                    'å…ˆè¿›ææ–™ ä¸­å›½'
                ]
            },
            
            # éŸ“å›½ã®ç‚­ç´ ç¹Šç¶­ãƒ»å…ˆé€²ææ–™ä¼æ¥­
            'korean_advanced_materials': {
                'keywords': ['íƒ„ì†Œì„¬ìœ ', 'ë³µí•©ì¬ë£Œ', 'ì²¨ë‹¨ì†Œì¬', 'carbon fiber', 'advanced materials'],
                'domains': ['hyosung.com', 'kctech.re.kr', 'kolon.com'],
                'search_terms': [
                    'íƒ„ì†Œì„¬ìœ  ì œì¡°ì—…ì²´ í•œêµ­',
                    'Korea carbon fiber companies',
                    'ì²¨ë‹¨ì†Œì¬ ê¸°ì—…',
                    'ë³µí•©ì¬ë£Œ í•œêµ­',
                    'advanced materials Korea'
                ]
            }
        }
        
        self.discovered_sources = []
        
    def search_category_sources(self, category_name: str, category_data: Dict) -> List[Dict]:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æƒ…å ±æºæ¢ç´¢"""
        print(f"ğŸ” {category_name} ã‚«ãƒ†ã‚´ãƒªã‚’æ¢ç´¢ä¸­...")
        
        category_sources = []
        
        for search_term in category_data['search_terms']:
            print(f"  æ¤œç´¢: {search_term}")
            
            # Googleæ¤œç´¢ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿéš›ã¯APIã‚„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰
            sources = self.simulate_search(search_term, category_data['keywords'])
            category_sources.extend(sources)
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            time.sleep(random.uniform(1, 3))
        
        return category_sources
    
    def simulate_search(self, search_term: str, keywords: List[str]) -> List[Dict]:
        """æ¤œç´¢çµæœã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®Ÿç’°å¢ƒã§ã¯å®Ÿéš›ã®æ¤œç´¢APIä½¿ç”¨ï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Google Custom Search API ã‚„ Bing Search API ã‚’ä½¿ç”¨
        simulated_results = []
        
        # ä¾‹: æ—¥æœ¬ã®ç‚­ç´ ç¹Šç¶­ãƒ¡ãƒ¼ã‚«ãƒ¼æ¤œç´¢çµæœ
        if 'ç‚­ç´ ç¹Šç¶­' in search_term or 'carbon fiber' in search_term:
            simulated_results = [
                {
                    'name': 'Kureha Corporation',
                    'domain': 'kureha.co.jp',
                    'url': 'https://www.kureha.co.jp',
                    'category': 'manufacturer',
                    'country': 'JP',
                    'description': 'ç‚­ç´ ç¹Šç¶­ãƒ»è¤‡åˆææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼',
                    'keywords_found': ['ç‚­ç´ ç¹Šç¶­', 'è¤‡åˆææ–™'],
                    'relevance_score': 0.85
                },
                {
                    'name': 'Nippon Graphite Fiber',
                    'domain': 'ngf-carbon.com',
                    'url': 'https://www.ngf-carbon.com',
                    'category': 'manufacturer',
                    'country': 'JP',
                    'description': 'ç‚­ç´ ç¹Šç¶­å°‚é–€ãƒ¡ãƒ¼ã‚«ãƒ¼',
                    'keywords_found': ['carbon fiber'],
                    'relevance_score': 0.90
                }
            ]
        
        # æ¬§å·ææ–™ãƒ¡ãƒ¼ã‚«ãƒ¼
        elif 'Europe' in search_term and 'materials' in search_term:
            simulated_results = [
                {
                    'name': 'Cytec Solvay Group',
                    'domain': 'cytec.com',
                    'url': 'https://www.cytec.com',
                    'category': 'manufacturer',
                    'country': 'BE',
                    'description': 'Advanced composite materials',
                    'keywords_found': ['composite materials', 'prepreg'],
                    'relevance_score': 0.88
                },
                {
                    'name': 'Owens Corning',
                    'domain': 'owenscorning.com',
                    'url': 'https://www.owenscorning.com',
                    'category': 'manufacturer',
                    'country': 'US',
                    'description': 'Fiberglass and composite materials',
                    'keywords_found': ['composite materials', 'fiber reinforced'],
                    'relevance_score': 0.82
                }
            ]
        
        # æ—¥æœ¬ã®ç”£æ¥­ãƒ¡ãƒ‡ã‚£ã‚¢
        elif 'è£½é€ æ¥­' in search_term or 'å°‚é–€ç´™' in search_term:
            simulated_results = [
                {
                    'name': 'Kogyo Newspaper',
                    'domain': 'kogyo.co.jp',
                    'url': 'https://www.kogyo.co.jp',
                    'category': 'media',
                    'country': 'JP',
                    'description': 'å·¥æ¥­å°‚é–€æ–°è',
                    'keywords_found': ['è£½é€ æ¥­', 'æŠ€è¡“'],
                    'relevance_score': 0.75
                },
                {
                    'name': 'Tech-On!',
                    'domain': 'techon.nikkeibp.co.jp',
                    'url': 'https://techon.nikkeibp.co.jp',
                    'category': 'media',
                    'country': 'JP',
                    'description': 'æŠ€è¡“æƒ…å ±ã‚µã‚¤ãƒˆ',
                    'keywords_found': ['æŠ€è¡“', 'ææ–™'],
                    'relevance_score': 0.80
                }
            ]
        
        # ä¸­å›½ã®è¤‡åˆææ–™
        elif 'å¤åˆææ–™' in search_term or ('China' in search_term and 'composites' in search_term):
            simulated_results = [
                {
                    'name': 'China Composite Materials',
                    'domain': 'composite.com.cn',
                    'url': 'https://www.composite.com.cn',
                    'category': 'media',
                    'country': 'CN',
                    'description': 'ä¸­å›½å¤åˆææ–™ä¸“ä¸šç½‘ç«™',
                    'keywords_found': ['å¤åˆææ–™', 'ç¢³çº¤ç»´'],
                    'relevance_score': 0.85
                },
                {
                    'name': 'Weihai Guangwei Composites',
                    'domain': 'gwcompos.com',
                    'url': 'https://www.gwcompos.com',
                    'category': 'manufacturer',
                    'country': 'CN',
                    'description': 'å¨æµ·å…‰å¨å¤åˆææ–™',
                    'keywords_found': ['å¤åˆææ–™', 'ç¢³çº¤ç»´'],
                    'relevance_score': 0.88
                }
            ]
        
        # éŸ“å›½ã®å…ˆé€²ææ–™
        elif 'íƒ„ì†Œì„¬ìœ ' in search_term or ('Korea' in search_term and 'materials' in search_term):
            simulated_results = [
                {
                    'name': 'Kolon Industries',
                    'domain': 'kolon.com',
                    'url': 'https://www.kolon.com',
                    'category': 'manufacturer',
                    'country': 'KR',
                    'description': 'ì½”ì˜¤ë¡± ì²¨ë‹¨ì†Œì¬',
                    'keywords_found': ['ì²¨ë‹¨ì†Œì¬', 'ë³µí•©ì¬ë£Œ'],
                    'relevance_score': 0.82
                },
                {
                    'name': 'Taekwang Industrial',
                    'domain': 'tkic.co.kr',
                    'url': 'https://www.tkic.co.kr',
                    'category': 'manufacturer',
                    'country': 'KR',
                    'description': 'íƒœê´‘ì‚°ì—… íƒ„ì†Œì„¬ìœ ',
                    'keywords_found': ['íƒ„ì†Œì„¬ìœ '],
                    'relevance_score': 0.80
                }
            ]
        
        return simulated_results
    
    def check_rss_availability(self, domain: str) -> str:
        """RSS/ãƒ•ã‚£ãƒ¼ãƒ‰å¯ç”¨æ€§ãƒã‚§ãƒƒã‚¯"""
        common_rss_paths = [
            '/rss.xml', '/feed.xml', '/rss/', '/feed/', 
            '/news/rss.xml', '/press/rss.xml', '/blog/rss.xml'
        ]
        
        for path in common_rss_paths:
            try:
                url = f"https://{domain}{path}"
                response = requests.head(url, timeout=10)
                if response.status_code == 200:
                    return url
            except:
                continue
        
        return None
    
    def evaluate_source_quality(self, source: Dict) -> Dict:
        """æƒ…å ±æºã®å“è³ªè©•ä¾¡"""
        score = 0
        reasons = []
        
        # é–¢é€£åº¦ã‚¹ã‚³ã‚¢
        relevance = source.get('relevance_score', 0)
        if relevance >= 0.8:
            score += 30
            reasons.append(f"é«˜ã„é–¢é€£åº¦ ({relevance:.2f})")
        elif relevance >= 0.6:
            score += 20
            reasons.append(f"ä¸­ç¨‹åº¦ã®é–¢é€£åº¦ ({relevance:.2f})")
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ä¿¡é ¼æ€§
        domain = source.get('domain', '')
        if domain.endswith(('.edu', '.org', '.gov')):
            score += 25
            reasons.append("ä¿¡é ¼ã§ãã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³")
        elif domain.endswith('.co.jp'):
            score += 15
            reasons.append("æ—¥æœ¬ä¼æ¥­ãƒ‰ãƒ¡ã‚¤ãƒ³")
        elif domain.endswith('.com'):
            score += 10
            reasons.append("ä¼æ¥­ãƒ‰ãƒ¡ã‚¤ãƒ³")
        
        # ã‚«ãƒ†ã‚´ãƒªä¾¡å€¤
        category = source.get('category', '')
        if category == 'manufacturer':
            score += 20
            reasons.append("ãƒ¡ãƒ¼ã‚«ãƒ¼æƒ…å ±æº")
        elif category == 'media':
            score += 15
            reasons.append("ãƒ¡ãƒ‡ã‚£ã‚¢æƒ…å ±æº")
        
        # RSSå¯ç”¨æ€§
        rss_url = self.check_rss_availability(source.get('domain', ''))
        if rss_url:
            score += 15
            reasons.append("RSSãƒ•ã‚£ãƒ¼ãƒ‰åˆ©ç”¨å¯èƒ½")
            source['rss_url'] = rss_url
        
        # å›½ãƒ»åœ°åŸŸã®ä¾¡å€¤
        country = source.get('country', '')
        if country in ['JP', 'DE', 'FR', 'BE']:
            score += 10
            reasons.append(f"é‡è¦åœ°åŸŸ ({country})")
        elif country in ['CN', 'KR']:
            score += 8
            reasons.append(f"ã‚¢ã‚¸ã‚¢é‡è¦åœ°åŸŸ ({country})")
        
        return {
            'score': score,
            'reasons': reasons,
            'approved': score >= 60,
            'review_required': 40 <= score < 60
        }
    
    def discover_all_categories(self) -> Dict:
        """å…¨ã‚«ãƒ†ã‚´ãƒªã®æ¢ç´¢å®Ÿè¡Œ"""
        print("ğŸš€ GPTã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹æƒ…å ±æºæ¢ç´¢é–‹å§‹")
        print("=" * 50)
        
        all_discovered = {}
        
        for category_name, category_data in self.categories.items():
            category_sources = self.search_category_sources(category_name, category_data)
            
            # å“è³ªè©•ä¾¡
            evaluated_sources = []
            for source in category_sources:
                evaluation = self.evaluate_source_quality(source)
                source['evaluation'] = evaluation
                evaluated_sources.append(source)
            
            all_discovered[category_name] = evaluated_sources
            print(f"  âœ“ {category_name}: {len(evaluated_sources)} å€‹ç™ºè¦‹")
        
        return all_discovered
    
    def generate_report(self, discovered_sources: Dict):
        """æ¢ç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"gpt_category_discovery_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# GPTã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹æƒ…å ±æºæ¢ç´¢ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"**å®Ÿè¡Œæ—¥æ™‚:** {datetime.now().isoformat()}\n\n")
            
            total_sources = sum(len(sources) for sources in discovered_sources.values())
            f.write(f"## ğŸ“Š æ¦‚è¦\n\n")
            f.write(f"- **æ¢ç´¢ã‚«ãƒ†ã‚´ãƒªæ•°:** {len(discovered_sources)}\n")
            f.write(f"- **ç™ºè¦‹æƒ…å ±æºç·æ•°:** {total_sources}\n\n")
            
            for category_name, sources in discovered_sources.items():
                f.write(f"## ğŸ“‚ {category_name}\n\n")
                
                approved = [s for s in sources if s['evaluation']['approved']]
                review = [s for s in sources if s['evaluation']['review_required']]
                
                f.write(f"- âœ… è‡ªå‹•æ‰¿èªå€™è£œ: {len(approved)}\n")
                f.write(f"- ğŸ” æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å€™è£œ: {len(review)}\n\n")
                
                if approved:
                    f.write("### âœ… è‡ªå‹•æ‰¿èªå€™è£œ\n\n")
                    for source in approved:
                        f.write(f"#### {source['name']}\n")
                        f.write(f"- **ãƒ‰ãƒ¡ã‚¤ãƒ³:** {source['domain']}\n")
                        f.write(f"- **å›½:** {source['country']}\n")
                        f.write(f"- **ã‚¹ã‚³ã‚¢:** {source['evaluation']['score']}\n")
                        f.write(f"- **RSS:** {source.get('rss_url', 'ãªã—')}\n")
                        f.write(f"- **èª¬æ˜:** {source['description']}\n\n")
        
        print(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        
        # å€™è£œSQLãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”Ÿæˆ
        self.generate_candidate_sql(discovered_sources, timestamp)
    
    def generate_candidate_sql(self, discovered_sources: Dict, timestamp: str):
        """å€™è£œæƒ…å ±æºã®SQLç”Ÿæˆ"""
        sql_file = f"gpt_discovered_sources_{timestamp}.sql"
        
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write("-- GPTã‚«ãƒ†ã‚´ãƒªæ¢ç´¢ã§ç™ºè¦‹ã•ã‚ŒãŸæƒ…å ±æº\n")
            f.write("-- è‡ªå‹•æ‰¿èªå€™è£œã®ã¿\n\n")
            
            for category_name, sources in discovered_sources.items():
                approved = [s for s in sources if s['evaluation']['approved']]
                
                if approved:
                    f.write(f"-- {category_name} ã‚«ãƒ†ã‚´ãƒª\n")
                    for source in approved:
                        rss_url = source.get('rss_url', f"https://{source['domain']}/rss.xml")
                        f.write(f"""
INSERT INTO sources (name, urls, parser, acquisition_mode, category, domain, country_code, relevance)
VALUES (
    '{source['name']}',
    ARRAY['{rss_url}'],
    'rss',
    'auto',
    '{source['category']}',
    '{source['domain']}',
    '{source['country']}',
    {min(10, max(1, source['evaluation']['score'] // 10))}
);
""")
        
        print(f"ğŸ’¾ SQLå€™è£œãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {sql_file}")

def main():
    discoverer = GPTCategoryDiscoverer()
    
    print("ğŸ” GPTã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹æƒ…å ±æºæ¢ç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    print("æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®é¡ä¼¼æƒ…å ±æºã‚’æ¢ç´¢ã—ã¾ã™")
    print()
    
    # å…¨ã‚«ãƒ†ã‚´ãƒªæ¢ç´¢å®Ÿè¡Œ
    discovered = discoverer.discover_all_categories()
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    discoverer.generate_report(discovered)
    
    # çµ±è¨ˆå‡ºåŠ›
    total_approved = sum(
        len([s for s in sources if s['evaluation']['approved']]) 
        for sources in discovered.values()
    )
    
    print(f"\nğŸ¯ æ¢ç´¢å®Œäº†!")
    print(f"è‡ªå‹•æ‰¿èªå€™è£œ: {total_approved} å€‹")
    print("ãƒ¬ãƒãƒ¼ãƒˆã¨SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()