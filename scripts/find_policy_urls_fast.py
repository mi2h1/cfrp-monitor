#!/usr/bin/env python3
"""
é«˜é€Ÿç‰ˆãƒãƒªã‚·ãƒ¼URLæ¤œç´¢ï¼ˆæ®‹ã‚Šã®ã‚½ãƒ¼ã‚¹ã®ã¿ï¼‰
ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ç¸®ãƒ»ä¸¦åˆ—å‡¦ç†ã§åŠ¹ç‡åŒ–
"""
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
from typing import Dict, List, Optional
from supabase import create_client, Client
from concurrent.futures import ThreadPoolExecutor, as_completed

# Supabaseæ¥ç¶š
supabase: Client = create_client(
    os.getenv("SUPABASE_URL"),
    os.getenv("SUPABASE_KEY")
)

class FastPolicyFinder:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # é«˜ç¢ºç‡ãƒ‘ã‚¹ã®ã¿ã«çµã‚Šè¾¼ã¿ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰
        self.priority_paths = [
            '/privacy', '/privacy-policy', '/terms', '/legal',
            '/privacy.html', '/privacy/', '/datenschutz'
        ]
    
    def get_sources_without_policy(self) -> List[Dict]:
        """policy_urlãŒæœªè¨­å®šã®ã‚½ãƒ¼ã‚¹ã®ã¿å–å¾—"""
        try:
            result = supabase.table("sources").select("id, name, domain").is_("policy_url", "null").execute()
            return result.data
        except Exception as e:
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def try_fast_paths(self, domain: str) -> Optional[str]:
        """é«˜é€Ÿãƒ‘ã‚¹è©¦è¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ç¸®ï¼‰"""
        base_url = f"https://{domain}"
        
        for path in self.priority_paths:
            url = f"{base_url}{path}"
            try:
                response = self.session.head(url, timeout=5, allow_redirects=True)
                if response.status_code == 200:
                    return url
            except:
                continue
        
        return None
    
    def search_homepage_links(self, domain: str) -> Optional[str]:
        """ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ã‹ã‚‰é«˜é€Ÿãƒªãƒ³ã‚¯æ¤œç´¢"""
        try:
            base_url = f"https://{domain}"
            response = self.session.get(base_url, timeout=8)
            if response.status_code != 200:
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ãƒ•ãƒƒã‚¿ãƒ¼ã®ã¿ã«é™å®šï¼ˆé«˜é€ŸåŒ–ï¼‰
            footer = soup.find('footer')
            if not footer:
                return None
            
            links = footer.find_all('a', href=True)
            
            policy_keywords = [
                'privacy', 'ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼', 'ä¸ªäººä¿¡æ¯', 'ê°œì¸ì •ë³´', 'datenschutz'
            ]
            
            for link in links:
                text = link.get_text().lower().strip()
                href = link.get('href')
                
                if any(keyword in text for keyword in policy_keywords):
                    return urljoin(base_url, href)
        
        except:
            pass
        
        return None
    
    def find_policy_for_source(self, source: Dict) -> Optional[str]:
        """å˜ä¸€ã‚½ãƒ¼ã‚¹ã®ãƒãƒªã‚·ãƒ¼URLæ¤œç´¢"""
        domain = source['domain']
        name = source['name']
        
        print(f"  ğŸ” {name} ({domain})")
        
        # 1. é«˜é€Ÿãƒ‘ã‚¹è©¦è¡Œ
        policy_url = self.try_fast_paths(domain)
        if policy_url:
            print(f"    âœ“ ç™ºè¦‹: {policy_url}")
            return policy_url
        
        # 2. ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ãƒªãƒ³ã‚¯æ¤œç´¢
        policy_url = self.search_homepage_links(domain)
        if policy_url:
            print(f"    âœ“ ç™ºè¦‹: {policy_url}")
            return policy_url
        
        print(f"    âŒ æœªç™ºè¦‹")
        return None
    
    def update_policy_url(self, source_id: int, policy_url: str) -> bool:
        """DBæ›´æ–°"""
        try:
            supabase.table("sources").update({
                "policy_url": policy_url
            }).eq("id", source_id).execute()
            return True
        except Exception as e:
            print(f"    âŒ DBæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def process_remaining_sources(self):
        """æ®‹ã‚Šã®ã‚½ãƒ¼ã‚¹ã‚’ä¸¦åˆ—å‡¦ç†"""
        sources = self.get_sources_without_policy()
        
        if not sources:
            print("âœ… å…¨ã¦ã®ã‚½ãƒ¼ã‚¹ã«policy_urlãŒè¨­å®šæ¸ˆã¿ã§ã™")
            return
        
        print(f"ğŸš€ æ®‹ã‚Š {len(sources)} å€‹ã®ã‚½ãƒ¼ã‚¹ã‚’é«˜é€Ÿå‡¦ç†")
        print("=" * 50)
        
        found_count = 0
        updated_count = 0
        
        # ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–ï¼ˆæœ€å¤§3ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_source = {
                executor.submit(self.find_policy_for_source, source): source 
                for source in sources
            }
            
            for future in as_completed(future_to_source):
                source = future_to_source[future]
                try:
                    policy_url = future.result()
                    
                    if policy_url:
                        found_count += 1
                        
                        # DBæ›´æ–°
                        if self.update_policy_url(source['id'], policy_url):
                            updated_count += 1
                        
                        # å°‘ã—é–“éš”ã‚’é–‹ã‘ã‚‹
                        time.sleep(1)
                
                except Exception as e:
                    print(f"    âŒ ã‚¨ãƒ©ãƒ¼ ({source['name']}): {e}")
        
        print("=" * 50)
        print(f"ğŸ¯ é«˜é€Ÿå‡¦ç†å®Œäº†: {found_count} å€‹ç™ºè¦‹, {updated_count} å€‹æ›´æ–°")
        
        return {
            'processed': len(sources),
            'found': found_count,
            'updated': updated_count
        }

def main():
    finder = FastPolicyFinder()
    
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv("SUPABASE_URL") or not os.getenv("SUPABASE_KEY"):
        print("âŒ ã‚¨ãƒ©ãƒ¼: SUPABASE_URL ã¨ SUPABASE_KEY ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return
    
    print("âš¡ é«˜é€ŸPolicy URL Discovery")
    print("æœªè¨­å®šã®ã‚½ãƒ¼ã‚¹ã®ã¿ã‚’ä¸¦åˆ—å‡¦ç†ã§é«˜é€Ÿæ¤œç´¢")
    print()
    
    # é«˜é€Ÿå‡¦ç†å®Ÿè¡Œ
    results = finder.process_remaining_sources()
    
    if results:
        print(f"\nâœ… é«˜é€Ÿå‡¦ç†å®Œäº†!")
        
        # æœ€çµ‚çŠ¶æ³ç¢ºèª
        print("\nğŸ“Š æœ€çµ‚ç¢ºèªä¸­...")
        time.sleep(2)
        
        all_sources = supabase.table("sources").select("policy_url").execute()
        filled = sum(1 for s in all_sources.data if s.get('policy_url'))
        total = len(all_sources.data)
        
        print(f"ğŸ“Š æœ€çµ‚çµæœ: {filled}/{total} å€‹ ({filled/total*100:.1f}%) ã«policy_urlè¨­å®šå®Œäº†")

if __name__ == "__main__":
    main()